{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Contextual Bandits: a rating environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook explore agents performance on a rating environment, also known as explicit feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import copy, deepcopy\n",
    "import random\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_argmax(rng, list_):\n",
    "    \"\"\" similar to np.argmax but return a random element among max\n",
    "        when multiple max exists.\"\"\"\n",
    "    return rng.choice(np.argwhere(list_ == list_.max()).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment\n",
    "The Multi-Armed Bandit setting is as follow: \n",
    "\n",
    "At each step you have to chose one arm to pull and recieve a reward accordingly.\n",
    "\n",
    "Here we consider Bernoulli rewards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExplicitFeedback:\n",
    "    \"\"\" A rating environment with explicit feedback.\n",
    "        User and items are represented by points in R^k\n",
    "        User interest for a given item is modeled by a parametric function\n",
    "        R_{u,i} = f(u,i) = f(W_u, W_i)\n",
    "        Example of function include dot product (cosine similarity)\n",
    "        R_{u,i} = \\sum_k w_{u,k} . w_{i,k}\n",
    "        action: Recommend one item for a given user among those he has never bought before\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, nb_users=30, nb_items=10, \n",
    "                 internal_embedding_size=3,\n",
    "                 displayed_users_embedding_size=2,\n",
    "                 displayed_items_embedding_size=2,\n",
    "                 noise_size=3,\n",
    "                 seed=None):\n",
    "        self.nb_users = nb_users\n",
    "        self.nb_items = nb_items\n",
    "        self.internal_embedding_size = internal_embedding_size\n",
    "        self.displayed_users_embedding_size = displayed_users_embedding_size\n",
    "        self.displayed_items_embedding_size = displayed_items_embedding_size\n",
    "        self.noise_size = noise_size\n",
    "        self._rng = np.random.RandomState(seed)\n",
    "        \n",
    "        self.action_size = self.nb_items\n",
    "        self.sampling_limit = nb_users * nb_items\n",
    "        self.user_mean = np.ones(self.internal_embedding_size)\n",
    "        self.user_var = np.ones(self.internal_embedding_size)\n",
    "        self.item_mean = np.ones(self.internal_embedding_size)\n",
    "        self.item_var = np.ones(self.internal_embedding_size)\n",
    "        self.users_embedding = None\n",
    "        self.items_embedding = None\n",
    "        self.user_item_history = None\n",
    "        self.z_cut_points = None\n",
    "        self.done = False\n",
    "\n",
    "    def step(self, action):\n",
    "        # check if behind done\n",
    "        if self.done: #self.user_item_history.sum() >= self.sampling_limit:\n",
    "            print(\"You are calling step after it return done=True.\\n\"\n",
    "                  \"You should reset the environment.\")\n",
    "\n",
    "        assert action < self.action_size\n",
    "        self.action = action\n",
    "        \n",
    "        # compute potential rewards\n",
    "        potential_rewards = [self._get_user_item_rating(self.current_user, i) \n",
    "                             for i in np.argwhere(self.user_item_history[self.current_user, :] == 0).flatten()]\n",
    "        \n",
    "        optimal_return = np.max(potential_rewards)\n",
    "\n",
    "        # map action to item\n",
    "        self.recommended_item = np.argwhere(self.user_item_history[self.current_user, :] == 0)[action][0]\n",
    "\n",
    "        # mark item as rated\n",
    "        self.user_item_history[self.current_user, self.recommended_item] = 1\n",
    "\n",
    "        # compute reward R_t\n",
    "        self.current_rating = self._get_user_item_rating(self.current_user, self.recommended_item)\n",
    "        self.reward = self.current_rating\n",
    "        \n",
    "        # check if done\n",
    "        if self.user_item_history.sum() == self.sampling_limit:\n",
    "            self.done = True\n",
    "\n",
    "        # compute next state S_{t+1}\n",
    "        self._next_state()\n",
    "\n",
    "        # update action space t+1\n",
    "        self.action_size = len(self.available_items)\n",
    "\n",
    "        return self.reward, self.state, self.done, optimal_return\n",
    "\n",
    "    def reset(self, seed=None):\n",
    "        self._rng = np.random.RandomState(seed)\n",
    "        self.action_size = self.nb_items\n",
    "        \n",
    "        # create users and items embedding matrix\n",
    "        self.users_embedding = self._rng.normal(loc=self.user_mean,\n",
    "                                                scale=self.user_var,\n",
    "                                                size=(self.nb_users, self.internal_embedding_size))\n",
    "        self.items_embedding = self._rng.normal(loc=self.item_mean,\n",
    "                                                scale=self.item_var,\n",
    "                                                size=(self.nb_items, self.internal_embedding_size))\n",
    "\n",
    "        # Let X = users_embedding and Y = items_embedding\n",
    "        # In order to properly map float into integers, we need to know the distribution of\n",
    "        # Z = \\sum_k X_k.Y_k\n",
    "        # E[Z] = \\sum_k E[X_k.Y_k] = \\sum_k E[X_k]E[Y_k]\n",
    "        # Var[Z] = \\sum_k Var[X_k.Y_k] = \\sum_k Var[X_k]Var[Y_k] + Var[X_k]E[Y_k]^2 + Var[Y_k]E[X_k]^2\n",
    "        z_mean = self.user_mean.dot(self.item_mean)\n",
    "        z_var = self.user_var.dot(self.item_var) + self.user_var.dot(np.square(self.item_mean)) + \\\n",
    "                self.item_var.dot(np.square(self.user_mean))\n",
    "        z = norm(z_mean, np.sqrt(z_var))\n",
    "        # to get 5 values, we need 4 cut points\n",
    "        self.z_cut_points = z.ppf([0.2, 0.4, 0.6, 0.8]) # you can control the distribution of ratings here.\n",
    "        self.user_item_history = np.zeros((self.nb_users, self.nb_items))\n",
    "        self.done = False\n",
    "\n",
    "        self._next_state()\n",
    "        return self.state\n",
    "\n",
    "    def _get_user_item_rating(self, user, item):\n",
    "        real_score = self.users_embedding[user].dot(self.items_embedding[item])\n",
    "        integer_score = np.searchsorted(self.z_cut_points, real_score) + 1\n",
    "        return integer_score\n",
    "\n",
    "    def _get_variables(self, user, item):\n",
    "        user_embedding = self.users_embedding[user]\n",
    "        item_embedding = self.items_embedding[item]\n",
    "        if self.displayed_users_embedding_size + self.displayed_items_embedding_size > 0:\n",
    "            variables = np.array([user_embedding[:self.displayed_users_embedding_size],\n",
    "                                  item_embedding[:self.displayed_items_embedding_size]])\n",
    "\n",
    "            if self.noise_size > 0:\n",
    "                noise = self._rng.normal(loc=np.ones(self.noise_size),\n",
    "                                         scale=np.ones(self.noise_size),\n",
    "                                         size=self.noise_size)\n",
    "                variables = np.append(variables, noise)\n",
    "\n",
    "            return variables\n",
    "\n",
    "    def _get_new_user(self):\n",
    "        for i in range(10):\n",
    "            user = self._rng.randint(0, self.nb_users)\n",
    "            # check it remain at least one item\n",
    "            if np.sum(self.user_item_history[user, :]) < self.nb_items:\n",
    "                return user\n",
    "        return self._rng.choice(np.argwhere(self.user_item_history == 0))[0]\n",
    "\n",
    "    def _next_state(self):\n",
    "        # Pick a user\n",
    "        if self.user_item_history.sum() < self.sampling_limit:\n",
    "            self.current_user = self._get_new_user()\n",
    "        else:\n",
    "            self.current_user = None\n",
    "\n",
    "        # List available items\n",
    "        self.available_items = np.argwhere(self.user_item_history[self.current_user, :] == 0)\n",
    "\n",
    "        self.state = list()\n",
    "        for i in self.available_items:\n",
    "            item = i[0]\n",
    "            # Compute variables\n",
    "            variables = self._get_variables(self.current_user, item)\n",
    "            self.state.append([self.current_user, item, variables])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ExplicitFeedback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[11, 0, array([ 0.69,  2.24,  1.32,  2.05, -0.35,  1.84,  2.02])],\n",
       " [11, 1, array([0.69, 2.24, 0.57, 1.12, 1.74, 1.14, 2.4 ])],\n",
       " [11, 2, array([0.69, 2.24, 0.03, 0.65, 0.34, 2.01, 1.88])],\n",
       " [11, 3, array([0.69, 2.24, 0.07, 1.55, 0.01, 0.36, 2.24])],\n",
       " [11, 4, array([0.69, 2.24, 0.75, 0.83, 1.44, 0.41, 0.95])],\n",
       " [11, 5, array([ 0.69,  2.24,  0.78,  0.72, -1.97,  0.14, -1.01])],\n",
       " [11, 6, array([ 0.69,  2.24, -1.49,  0.88,  2.08,  1.32,  0.86])],\n",
       " [11, 7, array([0.69, 2.24, 1.44, 0.5 , 0.32, 1.23, 0.48])],\n",
       " [11, 8, array([ 0.69,  2.24,  1.58, -0.06,  0.72,  3.18,  1.87])],\n",
       " [11, 9, array([0.69, 2.24, 2.16, 1.66, 3.14, 0.51, 2.85])]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset(seed=2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "user 11 is connecting to your platform and we shoud recommend him one item among the ten availables.\n",
    "We also observe a vector of features that could depend on the user, the item and/or some context(like time, weather, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward:  4\n"
     ]
    }
   ],
   "source": [
    "reward, next_state, done, optimal_return = env.step(0)\n",
    "print('reward: ', reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We recommend the first item of the list (item 0) to the user and he rate it 4 over 5.\n",
    "\n",
    "We also get the next state, that is the next user connect to our application, the list of available products for recommendations and a list of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0, array([ 0.35,  0.11,  1.32,  2.05,  0.42,  1.68, -0.08])],\n",
       " [1, 1, array([0.35, 0.11, 0.57, 1.12, 0.8 , 0.77, 0.59])],\n",
       " [1, 2, array([ 0.35,  0.11,  0.03,  0.65,  0.54, -0.05,  1.13])],\n",
       " [1, 3, array([0.35, 0.11, 0.07, 1.55, 1.68, 1.76, 0.1 ])],\n",
       " [1, 4, array([0.35, 0.11, 0.75, 0.83, 0.2 , 1.49, 1.95])],\n",
       " [1, 5, array([0.35, 0.11, 0.78, 0.72, 2.31, 2.89, 0.69])],\n",
       " [1, 6, array([ 0.35,  0.11, -1.49,  0.88, -0.37,  0.61,  0.69])],\n",
       " [1, 7, array([ 0.35,  0.11,  1.44,  0.5 , -0.72,  1.95,  1.32])],\n",
       " [1, 8, array([ 0.35,  0.11,  1.58, -0.06,  1.31,  1.26,  2.66])],\n",
       " [1, 9, array([ 0.35,  0.11,  2.16,  1.66,  3.16, -0.02,  0.28])]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User-Item recommender system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let start with a recommender system that use only user_id and item_id.\n",
    "\n",
    "But before let generate some historical data from a random agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent\n",
    "Here we create a very basic agent that will pull arm, i.e.play action, at random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Random:\n",
    "    \"\"\" Random agent. \"\"\"\n",
    "    def __init__(self, nb_arms, seed=None):\n",
    "        self._nb_arms = nb_arms\n",
    "        self._rng = np.random.RandomState(seed)\n",
    "        \n",
    "    def act(self, context):\n",
    "        action = self._rng.randint(len(context)) # note that action size is changing\n",
    "        return action\n",
    "        \n",
    "    def update(self, context, action, reward):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Random(None, seed=2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run experiment\n",
    "In order to make Agent and Environment interract, we can create an experiment, parametrized by the number of step we will be running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_exp(agent, env, nb_steps, env_seed):\n",
    "    rewards = np.zeros(nb_steps)\n",
    "    regrets = np.zeros(nb_steps)\n",
    "    actions = np.zeros(nb_steps)\n",
    "    context = env.reset(env_seed)\n",
    "    rating_matrix = np.zeros((env.nb_users, env.nb_items))\n",
    "    for i in range(nb_steps):\n",
    "        # Select action from agent policy.\n",
    "        action = agent.act(context)\n",
    "        \n",
    "        # Play action in the environment and get reward.\n",
    "        reward, next_context, done, optimal_return = env.step(action)\n",
    "        \n",
    "        # Update history\n",
    "        user = context[0][0]\n",
    "        item = context[action][1]\n",
    "        rating = reward\n",
    "        rating_matrix[user, item] = rating\n",
    "        \n",
    "        # Update agent.\n",
    "        agent.update(context, action, reward)\n",
    "        context = next_context\n",
    "        \n",
    "        # Save history.\n",
    "        #context[i] = context\n",
    "        rewards[i] = reward\n",
    "        actions[i] = action\n",
    "        regrets[i] = optimal_return - reward\n",
    "\n",
    "    reward = rewards.sum()\n",
    "    regret = np.sum(regrets)\n",
    "    return {'reward': reward, \n",
    "            'regret': regret,\n",
    "            'rewards': rewards,\n",
    "            'regrets': regrets,\n",
    "            'actions': actions,\n",
    "            'cum_rewards': np.cumsum(rewards), \n",
    "            'cum_regrets': np.cumsum(regrets),\n",
    "            'rating_matrix': rating_matrix\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example\n",
    "Let's run our previous agent and environment 100 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reward': 285.0,\n",
       " 'regret': 112.0,\n",
       " 'rewards': array([4., 2., 3., 2., 2., 2., 3., 2., 3., 2., 5., 2., 2., 3., 5., 2., 4.,\n",
       "        4., 5., 4., 2., 1., 1., 2., 3., 4., 2., 2., 1., 5., 2., 2., 2., 5.,\n",
       "        1., 2., 2., 2., 3., 3., 4., 4., 4., 4., 4., 4., 3., 2., 2., 2., 2.,\n",
       "        5., 3., 5., 3., 2., 4., 3., 2., 4., 4., 5., 3., 2., 2., 5., 3., 2.,\n",
       "        2., 3., 5., 4., 1., 3., 4., 2., 2., 5., 1., 1., 1., 4., 3., 4., 4.,\n",
       "        3., 2., 2., 4., 3., 3., 3., 2., 3., 2., 1., 2., 1., 2., 3.]),\n",
       " 'regrets': array([1., 0., 1., 3., 0., 2., 2., 3., 2., 0., 0., 0., 3., 2., 0., 0., 1.,\n",
       "        1., 0., 1., 0., 3., 1., 0., 1., 1., 3., 0., 1., 0., 3., 2., 2., 0.,\n",
       "        1., 1., 3., 1., 2., 1., 0., 1., 0., 0., 1., 1., 2., 0., 0., 3., 2.,\n",
       "        0., 1., 0., 1., 3., 1., 2., 0., 1., 1., 0., 0., 2., 0., 0., 2., 0.,\n",
       "        0., 2., 0., 1., 2., 2., 0., 2., 1., 0., 1., 1., 1., 1., 2., 1., 0.,\n",
       "        1., 2., 1., 1., 2., 1., 1., 2., 1., 1., 4., 1., 1., 2., 2.]),\n",
       " 'actions': array([0., 8., 3., 6., 3., 3., 7., 8., 0., 0., 8., 9., 3., 7., 2., 3., 6.,\n",
       "        5., 0., 4., 8., 6., 4., 1., 1., 7., 5., 5., 5., 6., 6., 6., 5., 4.,\n",
       "        6., 4., 2., 3., 4., 7., 1., 4., 1., 6., 3., 2., 0., 1., 1., 2., 2.,\n",
       "        7., 1., 0., 2., 8., 8., 5., 6., 3., 3., 2., 0., 0., 7., 6., 4., 6.,\n",
       "        6., 2., 6., 8., 7., 1., 5., 1., 9., 0., 1., 2., 3., 5., 0., 2., 1.,\n",
       "        3., 7., 7., 2., 5., 3., 0., 4., 0., 0., 3., 6., 3., 0., 5.]),\n",
       " 'cum_rewards': array([  4.,   6.,   9.,  11.,  13.,  15.,  18.,  20.,  23.,  25.,  30.,\n",
       "         32.,  34.,  37.,  42.,  44.,  48.,  52.,  57.,  61.,  63.,  64.,\n",
       "         65.,  67.,  70.,  74.,  76.,  78.,  79.,  84.,  86.,  88.,  90.,\n",
       "         95.,  96.,  98., 100., 102., 105., 108., 112., 116., 120., 124.,\n",
       "        128., 132., 135., 137., 139., 141., 143., 148., 151., 156., 159.,\n",
       "        161., 165., 168., 170., 174., 178., 183., 186., 188., 190., 195.,\n",
       "        198., 200., 202., 205., 210., 214., 215., 218., 222., 224., 226.,\n",
       "        231., 232., 233., 234., 238., 241., 245., 249., 252., 254., 256.,\n",
       "        260., 263., 266., 269., 271., 274., 276., 277., 279., 280., 282.,\n",
       "        285.]),\n",
       " 'cum_regrets': array([  1.,   1.,   2.,   5.,   5.,   7.,   9.,  12.,  14.,  14.,  14.,\n",
       "         14.,  17.,  19.,  19.,  19.,  20.,  21.,  21.,  22.,  22.,  25.,\n",
       "         26.,  26.,  27.,  28.,  31.,  31.,  32.,  32.,  35.,  37.,  39.,\n",
       "         39.,  40.,  41.,  44.,  45.,  47.,  48.,  48.,  49.,  49.,  49.,\n",
       "         50.,  51.,  53.,  53.,  53.,  56.,  58.,  58.,  59.,  59.,  60.,\n",
       "         63.,  64.,  66.,  66.,  67.,  68.,  68.,  68.,  70.,  70.,  70.,\n",
       "         72.,  72.,  72.,  74.,  74.,  75.,  77.,  79.,  79.,  81.,  82.,\n",
       "         82.,  83.,  84.,  85.,  86.,  88.,  89.,  89.,  90.,  92.,  93.,\n",
       "         94.,  96.,  97.,  98., 100., 101., 102., 106., 107., 108., 110.,\n",
       "        112.]),\n",
       " 'rating_matrix': array([[0., 0., 0., 2., 1., 1., 0., 0., 0., 0.],\n",
       "        [2., 0., 0., 0., 0., 0., 1., 0., 2., 0.],\n",
       "        [0., 0., 0., 0., 0., 3., 3., 3., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 5., 3., 0., 0.],\n",
       "        [0., 4., 0., 0., 3., 0., 1., 0., 0., 0.],\n",
       "        [0., 2., 2., 2., 2., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 5., 0., 0., 5., 2., 0.],\n",
       "        [3., 3., 2., 2., 3., 2., 0., 3., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 1., 2., 2., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 5., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 4., 0.],\n",
       "        [4., 0., 3., 0., 0., 0., 0., 0., 0., 5.],\n",
       "        [3., 0., 0., 0., 0., 4., 4., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 4., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 2., 0., 0., 0.],\n",
       "        [3., 4., 0., 2., 0., 3., 2., 0., 0., 0.],\n",
       "        [3., 5., 0., 0., 4., 4., 0., 0., 0., 0.],\n",
       "        [5., 0., 0., 0., 4., 0., 2., 0., 0., 5.],\n",
       "        [0., 0., 3., 0., 0., 3., 2., 0., 0., 0.],\n",
       "        [3., 0., 3., 2., 4., 0., 0., 0., 0., 0.],\n",
       "        [2., 0., 0., 0., 0., 0., 0., 2., 2., 2.],\n",
       "        [5., 0., 0., 0., 0., 0., 0., 0., 2., 0.],\n",
       "        [0., 0., 5., 2., 5., 4., 0., 3., 1., 0.],\n",
       "        [2., 0., 0., 0., 0., 2., 4., 0., 0., 0.],\n",
       "        [0., 0., 0., 2., 2., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 2., 0., 3., 0., 4., 2., 4.],\n",
       "        [0., 0., 1., 0., 0., 2., 0., 2., 2., 2.],\n",
       "        [3., 4., 0., 3., 0., 0., 0., 2., 0., 4.],\n",
       "        [0., 0., 4., 0., 0., 0., 0., 0., 2., 0.],\n",
       "        [0., 0., 4., 4., 0., 0., 0., 0., 0., 0.]])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_exp(agent, env, nb_steps=100, env_seed=2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that on this experiment the total reward is 285 and the regret is 112. You can also have a look at individual rewards, actions or regrets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to the historical data, we can train a matrix factorization algorithm to try to predict the non observed rating values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender system with historical data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> For the rest of this notebook, we will assume that when the Agent start it has access to some historical data generated by a random policy. </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix factorization\n",
    "Complete the two notebooks on [MovieLens dataset](https://github.com/thibaultallart/IA316-2020/blob/master/notebooks/3a_movieLens_dataset.ipynb) and [Collaborative filtering](https://github.com/thibaultallart/IA316-2020/blob/master/notebooks/3b_collaborative_filtering.ipynb) by Pascal Bianchi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Matrix factorization\n",
    "Complete this notebook on [Explicit Feedback Neural Recommender Systems](https://github.com/m2dsupsdlclass/lectures-labs/blob/master/labs/03_neural_recsys/Explicit_Feedback_Neural_Recommender_System.ipynb) by Olivier Grisel and Charles Ollion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice:\n",
    "1. Implement an Agent whose policy use a Matrix Factorization algorithm using the Alternating Least Squares from pypspark.\n",
    "2. Implement a similar Agent using embeddings in TensorFlow.\n",
    "3. Compare agents performances.\n",
    "4. Modify the Environment in order to return non linear rewards.\n",
    "5. Implement an deep recommender system Agent for explicit rewards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ALS agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Embedding Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Benchmark\n",
    "You can adapt the code below that look at the performance of a random Agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_exp = 100\n",
    "nb_steps = 100\n",
    "regret = np.zeros(nb_exp)\n",
    "regrets = np.zeros((nb_exp, nb_steps))\n",
    "for i in range(nb_exp):\n",
    "    env = ExplicitFeedback()\n",
    "    agent = Random(None, seed=i)\n",
    "    exp = run_exp(agent, env, nb_steps, env_seed=i)\n",
    "    regret[i] = exp['regret'] \n",
    "    regrets[i] = exp['cum_regrets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(regrets.mean(axis=0), color='blue')\n",
    "plt.plot(np.quantile(regrets, 0.05,axis=0), color='grey', alpha=0.5)\n",
    "plt.plot(np.quantile(regrets, 0.95,axis=0), color='grey', alpha=0.5)\n",
    "plt.title('Mean regret: {:.2f}'.format(regret.mean()))\n",
    "plt.xlabel('steps')\n",
    "plt.ylabel('regret')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Non linear rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Deep Agent"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
